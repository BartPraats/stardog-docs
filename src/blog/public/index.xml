<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>STARDOG★WEBLOG</title>
    <link>/</link>
    <description>Recent content on STARDOG★WEBLOG</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    
    
    <lastBuildDate>Thu, 06 Feb 2014 00:00:00 UTC</lastBuildDate>
    <atom:link href="/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Stardog World Tour</title>
      <link>/stardog-world-tour/</link>
      <pubDate>Thu, 06 Feb 2014 00:00:00 UTC</pubDate>
      
      <guid>/stardog-world-tour/</guid>
      <description>&lt;p&gt;We&amp;rsquo;re giving talks about &lt;a href=&#34;http://stardog.com&#34;&gt;Stardog&lt;/a&gt; at meetups on the East Coast over the next few months:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.meetup.com/semweb-31/events/163602752/&#34;&gt;Washington DC&lt;/a&gt;, February 18th at 6:30pm&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.meetup.com/MarylandSemantics/events/163753242/&#34;&gt;Baltimore MD&lt;/a&gt;, February 27th at 6:30pm&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.meetup.com/The-Philadelphia-Semantic-Web-Meetup/&#34;&gt;Philadephia PA&lt;/a&gt;, March 4th at 6:30pm&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.meetup.com/semweb-25/events/155269772/&#34;&gt;New York, NY&lt;/a&gt;, May 22nd at 6:30pm&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We&amp;rsquo;ll also be announcing dates in Northern Virginia, Boston, and
Toronto in the coming weeks. It&amp;rsquo;s a great opportunity to meet some of
the folks behind Stardog and learn more about it.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Scalability Improvements in Stardog 2.1</title>
      <link>/scalability-improvements-in-stardog-2.1/</link>
      <pubDate>Fri, 10 Jan 2014 00:00:00 UTC</pubDate>
      
      <guid>/scalability-improvements-in-stardog-2.1/</guid>
      <description>

&lt;p&gt;The forthcoming &lt;a href=&#34;http://stardog.com/&#34;&gt;Stardog 2.1&lt;/a&gt; release improves
query scalability by about 3 orders of magnitude and can handle 50
billion triples on a $10,000 server.~ We&amp;rsquo;ve never been overly
concerned about Stardog scalability per se: first we wanted to make it
easy to use; then we wanted to make it fast. We just assumed we&amp;rsquo;d get
around to make it &lt;em&gt;insanely scalable&lt;/em&gt;, too. Stardog 2.1 makes giant
leaps in query, data loading, and reasoning scalability.&lt;/p&gt;

&lt;p&gt;Running on $10,000 of server hardware (32 cores, 256 GB RAM), Stardog
2.1 can handle 20 to 50 billion triples. Compared to Stardog 2.0.x,
Stardog 2.1 loads ~100M triple datasets about two times faster; it
loads ~1B triple datasets about 3 times faster&amp;ndash;all while using much
less memory. 2.1 can load 20B datasets at 300,000 triples per
second. We also improved query evaluation performance significantly so
that Stardog 2.1 is still very fast, even at much larger database
sizes. How did we do it?&lt;/p&gt;

&lt;h2 id=&#34;improving-concurrency:221fb4795531eb14f0be5b8b2b42c9aa&#34;&gt;Improving Concurrency&lt;/h2&gt;

&lt;p&gt;Much of the performance improvement comes from taking care with
concurrency and reducing thread contention, especially during bulk
data loading (i.e., initial database creation with large amounts of
data being added at creation time). We&amp;rsquo;re avoiding more locks and
using more non-blocking algorithms and data structures a lot more
often. Moving for example from &lt;code&gt;BitSet&lt;/code&gt; to &lt;code&gt;ConcurrentLinkedQueue&lt;/code&gt;
helps, even though the former is more space efficient than the
later. We&amp;rsquo;re also using &lt;code&gt;ThreadLocal&lt;/code&gt;s more aggressively to reduce
thread contention and avoid synchronization. As loading performance
improved, several LRU caches became problematic since evictions were
being swamped by additions. Batching evictions in a single thread
helps but increases memory pressure and GC times.&lt;/p&gt;

&lt;h2 id=&#34;worse-hashing-is-better-hashing:221fb4795531eb14f0be5b8b2b42c9aa&#34;&gt;Worse Hashing is Better Hashing&lt;/h2&gt;

&lt;p&gt;Stardog hashes URIs, bnodes, and literal values for storage in a
mapping dictionary; previously we used the 64-bit &lt;code&gt;MurmurHash&lt;/code&gt; because
it&amp;rsquo;s very fast, has low collision rate, and lets us store values as
longs. When handling collisions and cache misses, disk accesses are
required; at scale these random disk accesses are too
expensive. Moving to &lt;code&gt;SHA1&lt;/code&gt; is perhaps non-intuitive since the hash
size goes from 64 to 160 bits. But since that makes hash collision
practically impossible, we&amp;rsquo;re able to achieve significant speedups&amp;ndash;it
also simplifies the mapping dictionary significantly.&lt;/p&gt;

&lt;h2 id=&#34;off-heap-memory-management:221fb4795531eb14f0be5b8b2b42c9aa&#34;&gt;Off-Heap Memory Management&lt;/h2&gt;

&lt;p&gt;Before 2.1, we were using &lt;code&gt;mmap&lt;/code&gt; aggressively during loading in order to use the operating system&amp;rsquo;s VM, memory management, etc. But memory mapped files in JVM are notoriously crappy (&lt;code&gt;unmap&lt;/code&gt;!), and we&amp;rsquo;ve seen frequent JVM crashes when we had a lot of memory mapped files around. Not good.&lt;/p&gt;

&lt;p&gt;We also realized that memory mapped files were causing performance slowdowns when there was more than 64GB of RAM available. And since we have no control over when memory mapped files were flushed to disk, that was typically happening too often. But keeping this information on the Java heap was never a viable choice at scale because of GC processing. Stardog 2.1 moves to an off-heap memory allocation scheme, which gives us very fine-grained control over disk flushes, uses available system memory more efficiently, and is (roughly) as fast as memory mapping.&lt;/p&gt;

&lt;h2 id=&#34;reducing-gc-pauses:221fb4795531eb14f0be5b8b2b42c9aa&#34;&gt;Reducing GC Pauses&lt;/h2&gt;

&lt;p&gt;Finally, to significantly improve loading performance we needed to do something about GC costs, which are important in bulk loading because of high rate of object creation and destruction. Using immutable objects makes it possible to improve concurrency but with the overhead of additional garbage being created. Tuning the GC knobs and buttons didn&amp;rsquo;t really help appreciably. We&amp;rsquo;ve addressed the GC processing costs by reworking places where we were unnecessarily creating objects. That kind of careful software engineering is aided by the relatively small size of the Stardog code base. It&amp;rsquo;s like engineering works or something!&lt;/p&gt;

&lt;p&gt;This careful software re-engineering included, for example, delving into the guts of the RDF parser to use a single &lt;code&gt;StringBuilder&lt;/code&gt; that was continuously reset rather than creating new builders for each RDF value. We also reduced the amount of cache use on the heap to relieve memory pressure. We now see GC pauses taking 1% or less of the overall bulk loading time.&lt;/p&gt;

&lt;h2 id=&#34;query-evaluation:221fb4795531eb14f0be5b8b2b42c9aa&#34;&gt;Query Evaluation&lt;/h2&gt;

&lt;p&gt;It doesn&amp;rsquo;t do much good to improve bulk data loading performance if
you don&amp;rsquo;t also improve query evaluation performance at least as
much. So we did that, too. The key to improving query evaluation
performance in 2.1 came down to memory usage and how we handle
intermediate results. Consider a SPARQL query from
&lt;a href=&#34;http://dbis.informatik.uni-freiburg.de/forschung/projekte/SP2B/&#34;&gt;SP2B&lt;/a&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;
SELECT DISTINCT ?name1 ?name2
  WHERE {
     ?article1 rdf:type bench:Article .
     ?article2 rdf:type bench:Article .
     ?article1 dc:creator ?author1 .
     ?author1 foaf:name ?name1 .
     ?article2 dc:creator ?author2 .
     ?author2 foaf:name ?name2 .
     ?article1 swrc:journal ?journal .
     ?article2 swrc:journal ?journal
  FILTER (?name1 &amp;lt; ?name2)
}&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;For a 5M triple database, this query produces 18,362,955 (!) results
and the &lt;code&gt;DISTINCT&lt;/code&gt; keeps them in memory. Unworkable at scale. Stardog
2.1 addresses this issue by reusing the new off-heap memory allocation
scheme. A small heap doesn&amp;rsquo;t work; and GC processing kills you with a
large heap, so we just avoid the heap instead. Yes, that means we have
to manage memory manually, but that&amp;rsquo;s actually achievable in a JVM
application. We implemented a memory manager based on various JVM
internals; it&amp;rsquo;s responsible for allocating (and deallocating) data
used during query evaluation, including holding intermediate query
results. It manages the heap outside the JVM and will flow to disk
when needed. The new memory manager also performs some static analysis
of the query using database statistics to guide its behavior.&lt;/p&gt;

&lt;h2 id=&#34;moving-forward:221fb4795531eb14f0be5b8b2b42c9aa&#34;&gt;Moving Forward&lt;/h2&gt;

&lt;p&gt;No public APIs were harmed in the creation of the new scalability
improvements. See
&lt;a href=&#34;http://presentboldly.com/kendall/stardog-21&#34;&gt;this slide deck&lt;/a&gt; for an
overview of some other changes in Stardog 2.1.&lt;/p&gt;

&lt;p&gt;Enjoy.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Stardog 1.2</title>
      <link>/stardog-1.2/</link>
      <pubDate>Mon, 22 Apr 2013 00:00:00 UTC</pubDate>
      
      <guid>/stardog-1.2/</guid>
      <description>

&lt;p&gt;Earlier today we released &lt;a href=&#34;http://stardog.com/&#34;&gt;&lt;strong&gt;Stardog 1.2&lt;/strong&gt;&lt;/a&gt; which
you can download for evaluation right now.&lt;/p&gt;

&lt;p&gt;Go on&amp;hellip;I&amp;rsquo;ll wait. Done? Awesome.&lt;/p&gt;

&lt;p&gt;So what&amp;rsquo;s new in Stardog 1.2? For the complete rundown, check out the
&lt;a href=&#34;http://stardog.com/docs/RELEASE_NOTES.txt&#34;&gt;changelog&lt;/a&gt;. Yeah, we&amp;rsquo;ve
been busy&amp;hellip;&lt;/p&gt;

&lt;h2 id=&#34;performance:c3f7361293cfc40f36deda2439cf8520&#34;&gt;Performance&lt;/h2&gt;

&lt;p&gt;As always, Stardog&amp;rsquo;s  performance is the most important feature. The 1.2 release is the fastest Stardog we&amp;rsquo;ve ever released. Performance improvements include:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;SPARQL query evaluation is faster, including a lower minimal overhead&lt;/li&gt;
&lt;li&gt;Durable transacted writes are faster&lt;/li&gt;
&lt;li&gt;Better caching of query plan rewritings improves reasoning perf&lt;/li&gt;
&lt;li&gt;Improved performance of write caching in transactions&lt;/li&gt;
&lt;li&gt;Applied better ordering to conjuncts makes reasoning query performance more deterministic&lt;/li&gt;
&lt;li&gt;Increased search indexing performance&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;query-management:c3f7361293cfc40f36deda2439cf8520&#34;&gt;Query Management&lt;/h2&gt;

&lt;p&gt;A new system for managing queries, which includes slow query logging, automatic query termination for queries that exceed a timeout, and query termination for queries by ID. This stuff makes deploying a public SPARQL endpoint backed by Stardog a lot easier, since long-running, rogue, or otherwise misbehaving queries can be managed effectively.&lt;/p&gt;

&lt;p&gt;The slow query log is configurable&amp;ndash;what counts as a slow query is interest-specific and user-relative. With slow query logging enabled, you can debug and then optimize slow queries.&lt;/p&gt;

&lt;p&gt;All of this is available in native Stardog APIs including Java, HTTP, and from the CLI.&lt;/p&gt;

&lt;h2 id=&#34;cli:c3f7361293cfc40f36deda2439cf8520&#34;&gt;CLI&lt;/h2&gt;

&lt;p&gt;The CLI is an important part of Stardog&amp;rsquo;s great user experience. To make it even better, we&amp;rsquo;ve completely rewritten it for the 1.2 release. The CLI is now more consistent (examples, arguments, response codes, etc), is self-documenting, more rational, and easier to manage. We&amp;rsquo;re also including Unix shell auto-completion support for the CLI.&lt;/p&gt;

&lt;p&gt;We&amp;rsquo;ve also added comprehensive &amp;ldquo;man pages&amp;rdquo; to the &lt;a href=&#34;http://stardog.com/docs/&#34;&gt;Stardog docs&lt;/a&gt; for all CLI commands.&lt;/p&gt;

&lt;h2 id=&#34;transactions:c3f7361293cfc40f36deda2439cf8520&#34;&gt;Transactions&lt;/h2&gt;

&lt;p&gt;We also developed a new, modular, standalone library for Stardog&amp;rsquo;s transactions; we call it &lt;code&gt;erg&lt;/code&gt;. It uses asynchronous writes &amp;amp; memory-mapped logs to improve durable logging performance. Transaction failure recovery has been improved. If there is a fatal error in a transaction commit or rollback, the database will be taken offline and recovery of the failed transaction will be performed. Recovery is automatic, and the database will be brought back online once it is completed.  In the event recovery could not be completed without manual intervention, the database will remain offline as to minimize data loss.&lt;/p&gt;

&lt;h2 id=&#34;security:c3f7361293cfc40f36deda2439cf8520&#34;&gt;Security&lt;/h2&gt;

&lt;p&gt;The security layer is completely rewritten. This includes a systematic (internal) security audit, tons of new tests, and generally smaller overhead for security processing. The result? Better security that&amp;rsquo;s faster and easier to manage.&lt;/p&gt;

&lt;p&gt;Other notable changes:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;user edit&lt;/code&gt; is replaced by &lt;code&gt;user addrole, removerole, disable, enable&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;LIST&lt;/code&gt; action is deprecated&lt;/li&gt;
&lt;li&gt;&lt;code&gt;REVOKE&lt;/code&gt; and &lt;code&gt;EXECUTE&lt;/code&gt; actions added&lt;/li&gt;
&lt;li&gt;Listing all users or roles requires different permissions&lt;/li&gt;
&lt;li&gt;Wildcards permitted when deleting permissions&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ADMIN&lt;/code&gt; resource for admin actions such as online &amp;amp; offline&lt;/li&gt;
&lt;li&gt;You must specify a password when creating a user&lt;/li&gt;
&lt;li&gt;Fixed vulnerability to billions laughs attacks&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;miscellaneous:c3f7361293cfc40f36deda2439cf8520&#34;&gt;Miscellaneous&lt;/h2&gt;

&lt;p&gt;Other improvements include:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;HTTP now supports SPARQL 1.1 Service Description&lt;/li&gt;
&lt;li&gt;Support for ARQ builtins &lt;code&gt;pi, e, sqrt, min, max&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Explanation system handles data inconsistencies&lt;/li&gt;
&lt;li&gt;Database, user, and role names now have a maximum size of 64
characters&lt;/li&gt;
&lt;li&gt;Updated to Sesame 2.7.0, Jena 2.10.0, Lucene 4.2.0, Shiro 1.2.1.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;stardog-2-0:c3f7361293cfc40f36deda2439cf8520&#34;&gt;Stardog 2.0&lt;/h2&gt;

&lt;p&gt;We&amp;rsquo;re pushing on Stardog 2.0 already and expect it to be released
sooner than later. More details about that later on. Big items coming
in 2.0 include Stardog Web&amp;ndash;a semantics-centric Javascript app
framework based on &lt;a href=&#34;http://backbonejs.org/&#34;&gt;Backbone.js&lt;/a&gt;&amp;ndash;complete
SPARQL Update support, and the open source release of Stardog client
libraries for Java.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Stardog: What&#39;s Coming Next?</title>
      <link>/stardog-whats-coming-next/</link>
      <pubDate>Thu, 27 Sep 2012 00:00:00 UTC</pubDate>
      
      <guid>/stardog-whats-coming-next/</guid>
      <description>

&lt;p&gt;Stardog is on the move; we got &lt;a href=&#34;http://stardog.com/&#34;&gt;Stardog
1.0&lt;/a&gt; out the door without anyone dying; we&amp;rsquo;ve got customers; people
are using it; and we released Stardog Community, too. Since the 1.0
release in June we&amp;rsquo;ve done 6 releases, about one every two weeks. Most
of them have focused on small usability improvements, performance
tweaks, and, of course, bug fixes.&lt;/p&gt;

&lt;p&gt;But where are we headed now with Stardog development?&lt;/p&gt;

&lt;h2 id=&#34;sparql-1-1:2341668b2be5b5fa620c1e2bfb4e4594&#34;&gt;SPARQL 1.1&lt;/h2&gt;

&lt;p&gt;The most pressing need in Stardog is support for
&lt;a href=&#34;http://www.w3.org/TR/sparql11-query/&#34;&gt;SPARQL 1.1&lt;/a&gt;. We got stuck
between the devil and the deep blue sea&amp;ndash;trying to push the 1.0
release before the SPARQL Working Group was completely finished with
the SPARQL 1.1 spec. We were motivated to avoid reimplementing any
parts of SPARQL 1.1 because the spec shifted. So we decided SPARQL 1.0
for the Stardog 1.0 release. Then we told everyone that SPARQL 1.1
would be the highest priority item for the post-1.0 release cycle.&lt;/p&gt;

&lt;p&gt;And so it&amp;rsquo;s been.&lt;/p&gt;

&lt;p&gt;As of this writing, Stardog TRUNK supports all of SPARQL 1.1 query
language; property paths are not totally finished but we&amp;rsquo;re close. We
already support a superset of the HTTP protocol for 1.1, so that&amp;rsquo;s
good.) Finishing property paths, final testing, and tweaking will take
a bit longer: we expect Stardog 1.1 release to be out by the end of
October. It will include full SPARQL 1.1 support.&lt;/p&gt;

&lt;p&gt;Except for the bits we don&amp;rsquo;t like.&lt;/p&gt;

&lt;p&gt;Frankly we&amp;rsquo;re nervous about adding update operations to SPARQL (the
query language; we already support update in our HTTP and SNARL
protocols) because we&amp;rsquo;re worried about SPARQL injection attacks. So
we&amp;rsquo;re going to take a bit more time to work out a secure design for
supporting update operations in the query language. Stay tuned for
those bits some time after the 1.1 release.&lt;/p&gt;

&lt;h2 id=&#34;user-defined-rules-and-reasoning:2341668b2be5b5fa620c1e2bfb4e4594&#34;&gt;User-defined Rules and Reasoning&lt;/h2&gt;

&lt;p&gt;Stardog already has the best and most comprehensive OWL 2 reasoning of
any RDF database; but we&amp;rsquo;re not finished making it better. In Stardog
1.1 we&amp;rsquo;ll debut user-defined rule reasoning; some domain modeling just
doesn&amp;rsquo;t fit easily into OWL axioms. &lt;strong&gt;Sometimes you really need to
write a damn rule!&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Stardog 1.1 will support user-defined rules using the SWRL syntax; it
will include all of the SWRL builtins, as well as a much-requested new
builtin that allows SWRL rules to create new individuals. (Strictly
speaking, this new builtin is a gun with which users may easily shoot
themselves a &lt;em&gt;non-terminating&lt;/em&gt; wound. Don&amp;rsquo;t say you weren&amp;rsquo;t warned!)&lt;/p&gt;

&lt;p&gt;Finally, we&amp;rsquo;ve added a Datalog engine to Stardog and we&amp;rsquo;ll use that to
support the rest of OWL 2; that is, we&amp;rsquo;ll use the new Datalog engine
to support transitivity (first) and (later) equality reasoning.&lt;/p&gt;

&lt;h2 id=&#34;performance:2341668b2be5b5fa620c1e2bfb4e4594&#34;&gt;Performance&lt;/h2&gt;

&lt;p&gt;SPARQL query performance is our primary obsession these days,
especially for very complex queries involving lots of joins, etc. We
think answering complex queries is the sweet spot for SPARQL and
RDF-based information systems. And since we reduce OWL reasoning to
SPARQL query answering (more or less), we have additional motivation
to make it really fast.&lt;/p&gt;

&lt;p&gt;We&amp;rsquo;ve pushed many SPARQL FILTER operations down further into query
evaluation, with the result that in many cases queries with FILTERs
are much faster. We&amp;rsquo;ve also improved database write performance&amp;ndash;which
is, admittedly, a lower priority than database read performance&amp;ndash;by
being more clever with how we torture the disk head. We&amp;rsquo;ve also
increased Stardog write safety during system instability (power cord
got yanked?!) by writing more aggressively and more often to
disk. Finally, we&amp;rsquo;re looking at some new data compression techniques
that may let us speed up disk reads substantially.&lt;/p&gt;

&lt;h2 id=&#34;production-features:2341668b2be5b5fa620c1e2bfb4e4594&#34;&gt;Production Features&lt;/h2&gt;

&lt;p&gt;We&amp;rsquo;re working on hot backup, i.e., backing up a Stardog database
without having to take it offline. We&amp;rsquo;ll add that to the JMX
monitoring that&amp;rsquo;s been sitting in a branch for nearly 9 months; the
new query management subsystem; and the long-awaited web
console. These production features will make life easier for the
operations people in yr life.&lt;/p&gt;

&lt;h2 id=&#34;geospatial-query-answering:2341668b2be5b5fa620c1e2bfb4e4594&#34;&gt;Geospatial Query Answering&lt;/h2&gt;

&lt;p&gt;Finally, geospatial query answering and reasoning are coming to
Stardog. We&amp;rsquo;re implementing GeoSPARQL and, while it&amp;rsquo;s still very early
in the development cycle, we&amp;rsquo;re excited and confident it&amp;rsquo;ll be a very
useful addition.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Stardog 1.0</title>
      <link>/stardog-1.0/</link>
      <pubDate>Mon, 18 Jun 2012 00:00:00 UTC</pubDate>
      
      <guid>/stardog-1.0/</guid>
      <description>

&lt;p&gt;Today I&amp;rsquo;m happy to announce the release of &lt;a href=&#34;http://stardog.com/&#34;&gt;Stardog
1.0&lt;/a&gt;, the fastest, smartest, and easiest to use RDF
database on the planet. Stardog fills a hole in the Semantic Technology
(and NoSQL database) market for an RDF database that is fast, zero config,
lightweight, and feature-rich.&lt;/p&gt;

&lt;h2 id=&#34;speed-kills:9635592bbc40647e0cbf69b34e68feb4&#34;&gt;Speed Kills&lt;/h2&gt;

&lt;p&gt;RDF and OWL are excellent technologies for building data integration and
analysis apps. Those apps invariably require complex query processing,
i.e., queries where there are lots of joins, complex logical conditions to
evaluate, etc. Stardog is targeted at query performance for &lt;em&gt;complex SPARQL
queries&lt;/em&gt;. We publish &lt;a href=&#34;http://stardog.com/docs/performance&#34;&gt;performance data&lt;/a&gt;
so you can see how we&amp;rsquo;re doing.&lt;/p&gt;

&lt;h2 id=&#34;braindead-simple-deployment:9635592bbc40647e0cbf69b34e68feb4&#34;&gt;Braindead Simple Deployment&lt;/h2&gt;

&lt;p&gt;Winners ship. Period.&lt;/p&gt;

&lt;p&gt;We care very much about simple deployments. Stardog works out-of-the-box
with minimal (none, typically) configuration. You shouldn&amp;rsquo;t have to fight an
RDF database for days to install or tune it for great performance. Because
Stardog is pure Java, it will run anywhere. It &lt;em&gt;just works&lt;/em&gt; and it&amp;rsquo;s &lt;em&gt;damn
fast&lt;/em&gt;. You shouldn&amp;rsquo;t need to buy and configure a cluster of machines to get
blazing fast performance from an RDF database. And now you don&amp;rsquo;t have to.&lt;/p&gt;

&lt;h2 id=&#34;one-more-thing-owl-reasoning:9635592bbc40647e0cbf69b34e68feb4&#34;&gt;One More Thing&amp;hellip;OWL Reasoning&lt;/h2&gt;

&lt;p&gt;Finally, Stardog has the deepest, most comprehensive, and best OWL reasoning
support of any commerical RDF database available.&lt;/p&gt;

&lt;p&gt;Stardog 1.0 supports RDFS, OWL 2 QL, EL, and RL, as well as OWL 2 DL
schema-reasoning. It&amp;rsquo;s also the only RDF database to support closed-world
integrity constraint validation and automatic explanations of integrity constraint
violations.&lt;/p&gt;

&lt;p&gt;If you care about data quality, Stardog 1.0 is worth a hard look.&lt;/p&gt;

&lt;h2 id=&#34;free-evaluation:9635592bbc40647e0cbf69b34e68feb4&#34;&gt;Free Evaluation&lt;/h2&gt;

&lt;p&gt;Stardog 1.0 is available for a free 30-day evaluation; &lt;a href=&#34;http://stardog.com/dl&#34;&gt;download it
now&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;When you&amp;rsquo;re ready to talk about licensing terms and support contracts, drop
us an &lt;a href=&#34;mailto:sales@clarkparsia.com&#34;&gt;email&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Stardog 0.9 Release</title>
      <link>/stardog-0.9-release/</link>
      <pubDate>Thu, 23 Feb 2012 00:00:00 UTC</pubDate>
      
      <guid>/stardog-0.9-release/</guid>
      <description>&lt;p&gt;We&amp;rsquo;re happy to announce the release of &lt;strong&gt;Stardog 0.9&lt;/strong&gt;, the first
&lt;em&gt;feature-complete&lt;/em&gt; version of Stardog. Please
&lt;a href=&#34;http://stardog.com/&#34;&gt;download&lt;/a&gt; it and send feedback to the
&lt;a href=&#34;https://groups.google.com/a/clarkparsia.com/group/stardog/about&#34;&gt;support forum&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Notable changes in this release:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;new security system, including user management, granular roles and permissions model&lt;/li&gt;
&lt;li&gt;new native protocol, SNARL, based on Netty and Google&amp;rsquo;s Protocol Buffers&lt;/li&gt;
&lt;li&gt;new system catalog for all system info, metadata, etc.&lt;/li&gt;
&lt;li&gt;new search system over RDF literals, integrated with SPARQL query eval&lt;/li&gt;
&lt;li&gt;new server management: online, offline databases; better server startup, shutdown, and locking&lt;/li&gt;
&lt;li&gt;CLI now supports remote db administration, many new subcommands&lt;/li&gt;
&lt;li&gt;new Quartz-based job scheduler with cron expression scheduling&lt;/li&gt;
&lt;li&gt;new, optimized index support for named graphs and triples-only databases&lt;/li&gt;
&lt;li&gt;new, differential write indexes with customizable merge thresholds&lt;/li&gt;
&lt;li&gt;new statistics computation &amp;amp; recomputation algorithms&lt;/li&gt;
&lt;li&gt;new customizable TBOX (i.e., reasoning schema or ontology) extraction &amp;amp; management&lt;/li&gt;
&lt;li&gt;new Stardog configuration system, including database creation templates&lt;/li&gt;
&lt;li&gt;new reasoning services (explanation, satisfiability, consistency checking) available programmatically&lt;/li&gt;
&lt;li&gt;reasoning extended to named graphs&lt;/li&gt;
&lt;li&gt;ICV validation extended to named graphs&lt;/li&gt;
&lt;li&gt;new or improved support for NQUADS, Trig, TSV, and CSV&lt;/li&gt;
&lt;li&gt;improved concurrency in data loading&lt;/li&gt;
&lt;li&gt;consistent use of &lt;tt&gt;mmap()&lt;/tt&gt; for better performance&lt;/li&gt;
&lt;li&gt;load GZIP-compressed files directly, including ZIP files with multiple RDF&lt;/li&gt;
&lt;li&gt;many (many!) known bugs fixed&lt;/li&gt;
&lt;li&gt;updated documentation&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The upcoming 0.9.x releases will focus on query and reasoning
performance improvements and bug fixes. We anticipate several point
releases before the final 1.0 release. Thanks to all the &lt;em&gt;closed
alpha&lt;/em&gt; testers for their hard work: about 200 of them downloaded
Stardog, sent bug reports, fixes, ideas, and feedback.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Stardog Performance: SP2B Benchmark</title>
      <link>/stardog-performance-sp2b-benchmark/</link>
      <pubDate>Tue, 31 May 2011 00:00:00 UTC</pubDate>
      
      <guid>/stardog-performance-sp2b-benchmark/</guid>
      <description>

&lt;p&gt;As you may already know, we&amp;rsquo;re working hard on
&lt;a href=&#34;http://stardog.com/&#34;&gt;Stardog&lt;/a&gt;, our upcoming RDF database. It&amp;rsquo;s presently
in closed alpha testing (55 testers), at version 0.5.3, and progressing
rapidly. The overriding goals for Stardog, which we&amp;rsquo;ve repeated often, are:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;insanely fast performance on complex SPARQL queries in the out-of-the-box, untuned configuration&lt;/li&gt;
&lt;li&gt;feature-rich: logical inference, statistical inference, transactions, store procedures, etc.&lt;/li&gt;
&lt;li&gt;lightweight and pure Java&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;We think we&amp;rsquo;re on track to meet those goals for a 1.0 release in Q3, 2011.&lt;/p&gt;

&lt;p&gt;In advance of Mike Grove&amp;rsquo;s
&lt;a href=&#34;http://semtech2011.semanticweb.com/sessionPop.cfm?confid=62&amp;amp;proposalid=3943&#34;&gt;talk&lt;/a&gt; next week at Semantic Technology Conference 2011, and since the
&lt;a href=&#34;http://blog.dydra.com/2011/05/27/sp2b-benchmarks&#34;&gt;Dydra peeps&lt;/a&gt; are
publishing SP2B benchmark numbers, too, I thought we&amp;rsquo;d say a bit about
Stardog performance.&lt;/p&gt;

&lt;h2 id=&#34;sp2b-benchmark-performance:df6b2706cc1f69991ab85433409eec46&#34;&gt;SP2B Benchmark Performance&lt;/h2&gt;

&lt;p&gt;In short, it&amp;rsquo;s pretty awesome. We&amp;rsquo;re reporting SP2B&amp;ndash;the leading SPARQL
benchmark for complex, real-world performance&amp;ndash;results that are noteworthy.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://dl.dropbox.com/u/126772/stardog-perf.png&#34;&gt;&lt;/p&gt;

&lt;p&gt;As you can see, we&amp;rsquo;re reporting SP2B benchmarks for six dataset sizes: 10k,
50k, 250k, 1M, 5M, and 25M. We&amp;rsquo;re not aware of any RDF database previously
reporting &lt;em&gt;any&lt;/em&gt; numbers for 25M SP2B dataset size. Note, too, that the
y-axis is logarithmic in &lt;em&gt;milliseconds&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;With the exception of query Q5a&amp;ndash;about which more below&amp;ndash;the performance
numbers are quite good; the benchmark machine was quite modest (an iMac
with 2 i7s using 8GB RAM), a bit under-powered in comparison to the average
production machine these days.&lt;/p&gt;

&lt;p&gt;In particular, note Q7, which Stardog evaluates for 1M dataset in less than
1 second; at 5M in about 5 seconds; and at 25M&amp;ndash;which no other RDF database
has reported &lt;em&gt;any&lt;/em&gt; performance numbers&amp;ndash;in about 12 seconds. For Q4, at 5M,
Stardog completes in 45 seconds. The next fastest RDF database, for which
SP2B results have been reported, completes Q4 for 1M dataset in 134 seconds.&lt;/p&gt;

&lt;h2 id=&#34;state-of-the-art:df6b2706cc1f69991ab85433409eec46&#34;&gt;State of the Art&lt;/h2&gt;

&lt;p&gt;A brief word about SP2B query Q5a; despite what Arto &lt;a href=&#34;http://blog.dydra.com/2011/05/27/sp2b-benchmarks&#34;&gt;said
recently&lt;/a&gt;, we don&amp;rsquo;t
believe there&amp;rsquo;s any mistake in the SP2B benchmark for Q5a. It is simply
a very hard query, requiring the detection of an implicit join for good
performance.&lt;/p&gt;

&lt;p&gt;We&amp;rsquo;re not aware of any RDF database that is able to detect this implicit
join &lt;em&gt;generally&lt;/em&gt;. Stardog has an optimization that detects it for Q5a and
for similar queries, which will be available in a future release, pending
some additional engineering. These benchmark results do not include that
optimization.&lt;/p&gt;

&lt;h2 id=&#34;conclusion:df6b2706cc1f69991ab85433409eec46&#34;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;It&amp;rsquo;s an exciting time to be a semantic technology
vendor, especially in the &lt;a href=&#34;http://weblog.clarkparsia.com/2010/09/23/the-rdf-database-market/&#34;&gt;RDF database
market&lt;/a&gt; which
is still seeing rapid innovation and maturation. We&amp;rsquo;re happy that the
Dydra folks are using SP2B as a benchmark; we agree with them that SP2B
is the &amp;ldquo;gold standard of SPARQL benchmarks&amp;rdquo; and will continue to develop
&lt;a href=&#34;http://stardog.com/&#34;&gt;Stardog&lt;/a&gt; with SP2B as one measure of progress among
many.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Invitation to Stardog Beta</title>
      <link>/invitation-to-stardog-beta/</link>
      <pubDate>Mon, 10 Jan 2011 00:00:00 UTC</pubDate>
      
      <guid>/invitation-to-stardog-beta/</guid>
      <description>

&lt;p&gt;&lt;strong&gt;TL;DR?&lt;/strong&gt; &lt;a href=&#34;http://stardog.com/&#34;&gt;Stardog&lt;/a&gt; is a fast, lightweight RDF
database. Today we&amp;rsquo;re announcing limited access to our beta testing program,
in preparation for the 1.0 release. If you&amp;rsquo;re interested in beta-testing
Stardog, &lt;a href=&#34;mailto:kendall@clarkparsia.com&#34;&gt;drop me an email&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;what-and-why:031f92451d7409c107d8dac8c3792baf&#34;&gt;What and why?&lt;/h2&gt;

&lt;p&gt;There&amp;rsquo;s a niche in the &lt;a href=&#34;http://weblog.clarkparsia.com/2010/09/23/the-rdf-database-market/&#34;&gt;RDF commercial
market&lt;/a&gt;
that&amp;rsquo;s not well-served&amp;ndash;we built Stardog to fill this niche. After testing
many RDF databases, we couldn&amp;rsquo;t find one that was exactly right for the use
cases and requirements that we care about: zero config, fast, transactional,
lightweight, embeddable, client-server, high-throughput, rich OWL 2
reasoning, stored procedures in any JVM-based language RDF database. Whew!&lt;/p&gt;

&lt;h2 id=&#34;speed-kills:031f92451d7409c107d8dac8c3792baf&#34;&gt;Speed Kills&lt;/h2&gt;

&lt;p&gt;RDF and OWL are excellent technologies for building data integration and
analysis apps. Those apps invariably require complex query processing,
i.e., queries where there are lots of joins, complex logical conditions
to evaluate, etc. Stardog is targeted at absolute query performance for
&lt;em&gt;complex SPARQL queries&lt;/em&gt;.&lt;/p&gt;

&lt;h2 id=&#34;lightweight-braindead-simple-deployment:031f92451d7409c107d8dac8c3792baf&#34;&gt;Lightweight, Braindead Simple Deployment&lt;/h2&gt;

&lt;p&gt;Winners ship. No excuses. No one wants complex deployment models. Stardog
works out-of-the-box with minimal (none, typically) configuration. You
shouldn&amp;rsquo;t have to fight to install or to tune an RDF database for days.
Because Stardog is pure Java, it will run anywhere, in any servlet
container, on any OS.&lt;/p&gt;

&lt;h2 id=&#34;owl-2-reasoning:031f92451d7409c107d8dac8c3792baf&#34;&gt;OWL 2 Reasoning&lt;/h2&gt;

&lt;p&gt;Finally, Stardog has the most comprehensive and best OWL reasoning support
of any commercial RDF database available.&lt;/p&gt;

&lt;p&gt;Stardog 1.0 will support: SPARQL 1.1 entailment regimes,
&lt;a href=&#34;http://weblog.clarkparsia.com/2010/04/01/pellet21-terp/&#34;&gt;Terp&lt;/a&gt;, OWL 2 DL
schema reasoning via &lt;a href=&#34;http://clarkparsia.com/pelletdb/&#34;&gt;PelletDb&lt;/a&gt;, OWL 2
QL (query-time reasoning), and OWL 2 closed world reasoning via &lt;a href=&#34;http://clarkparsia.com/pellet/icv/&#34;&gt;Pellet
ICV&lt;/a&gt;. We&amp;rsquo;ll add OWL 2 RL support to
Stardog in a future release.&lt;/p&gt;

&lt;p&gt;Okay, there&amp;rsquo;s a lot there and we&amp;rsquo;ll unpack it all in good time; but for now
the point is that Stardog&amp;rsquo;s reasoning support is not only more comprehensive
than any other RDF database, it&amp;rsquo;s more consistent, rational, and tied
carefully to the W3C&amp;rsquo;s OWL 2 standard. Stardog also encompasses all the
relevant points on the scalability-expressivity spectrum, as well as hitting
all of the significant reasoning modes of operation (batch, on-demand,
query-time).&lt;/p&gt;

&lt;h2 id=&#34;next-steps:031f92451d7409c107d8dac8c3792baf&#34;&gt;Next Steps&lt;/h2&gt;

&lt;p&gt;We&amp;rsquo;re running a limited, private beta for Stardog starting 1 March and
running to 30 May. We&amp;rsquo;ve got a few open slots, and we want to cast a
wide net to find some new orgs and new faces with new use cases and
requirements for a commercial RDF database. If you&amp;rsquo;re interested, &lt;a href=&#34;mailto:kendall@clarkparsia.com&#34;&gt;drop me
an email&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>The RDF Database Market</title>
      <link>/the-rdf-database-market/</link>
      <pubDate>Thu, 23 Sep 2010 00:00:00 UTC</pubDate>
      
      <guid>/the-rdf-database-market/</guid>
      <description>

&lt;p&gt;Update: &lt;a href=&#34;http://stardog.com/&#34;&gt;Stardog&lt;/a&gt; is our entry into the
commercial RDF database market.&lt;/p&gt;

&lt;p&gt;There&amp;rsquo;s plenty of talk about the purely technical aspects of RDF databases
but considerably less talk about the &lt;em&gt;RDF database market&lt;/em&gt; as a commercial
software business.~ As I see it, the commercial RDF database market contains
at least seven systems, listed here in random order:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.oracle.com/technetwork/database/options/semantic-tech/index.html&#34;&gt;Oracle&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://virtuoso.openlinksw.com/&#34;&gt;Virtuoso&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.franz.com/agraph/allegrograph/&#34;&gt;AllegroGraph&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.systap.com/bigdata.htm&#34;&gt;BigData&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.ontotext.com/owlim/&#34;&gt;OWLIM&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://4store.org/trac/wiki/5store&#34;&gt;5Store&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.talis.com/platform/&#34;&gt;Talis Platform&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;There are another 8 to 10 &lt;em&gt;technically viable RDF databases
available&lt;/em&gt;. However, I want to talk about these seven systems as
comprising the &lt;em&gt;commercial market&lt;/em&gt;, by which I mean systems that
satisfy two conditions: first, they are production-ready; and, second, they
are commercially licensed (that is, you have to pay money to use them). A
weaker version of the latter condition, which I&amp;rsquo;m happy with, is just
that there is a single entity which owns the system (i.e., they are not
community-owned) and that entity is commercial (i.e., profit-seeking) in
nature.&lt;/p&gt;

&lt;p&gt;Most of these systems have a zero-cost version or are open-source
licensed. But they also all have commercial editions or commercial add-ons,
extensions, etc. (BigData is a variant: it&amp;rsquo;s using the dual licensing (GPL
and commercial) model.) I also know that SDB, TDB, Sesame, and plenty of
others are production-ready, but none of them is commercially licensed, to
my knowledge&amp;mdash;please post a comment if I&amp;rsquo;ve got that wrong.&lt;/p&gt;

&lt;p&gt;A final qualification: the 5Store site says that it &amp;ldquo;may be possible to
license&amp;rdquo; it from Garlik. My guess (and it&amp;rsquo;s only a guess) is that it&amp;rsquo;s
more likely if you aren&amp;rsquo;t licensing it in order to compete with Garlik&amp;rsquo;s
commercial service offerings. I will just assume, however, that 5Store is
licensable generally.&lt;/p&gt;

&lt;p&gt;I don&amp;rsquo;t want to quibble about the contours of the definition; rather, I want
to speculate about how we might rank these systems in terms of commercial
impact; that is, who&amp;rsquo;s earning the most revenue from license sales of these
systems, what are some of the features of the commercial market with respect
to messaging and positioning, etc.&lt;/p&gt;

&lt;h2 id=&#34;no-pure-plays:aedb8a7ea38a4e095f87fc7c5e54b3a9&#34;&gt;No Pure Plays&lt;/h2&gt;

&lt;p&gt;The first point to make is that there are no &lt;em&gt;pure plays&lt;/em&gt;
here. BigData comes the closest to being a pure RDF database play; but
since it&amp;rsquo;s currently GPL&amp;rsquo;d, it may be the case that its development is
being subsidized via commercial activities other than software licensing. I
hope Systap is licensing BigData and its extensions; but they may well be
generating revenue from customizations, installations, or other service
revenue.&lt;/p&gt;

&lt;p&gt;Every other system is the product of either a larger software enterprise
(Virtuoso, AllegroGraph, OWLIM, Talis Platform), a &lt;em&gt;much&lt;/em&gt; larger
software enterprise (Oracle), or a related business (5Store, which is
available from Garlik, a personal information management service in the UK).&lt;/p&gt;

&lt;p&gt;I don&amp;rsquo;t know of any RDF database produced as a pure play biz model. I don&amp;rsquo;t
know what that means, if anything, but it&amp;rsquo;s worth noting. Put another
way: if that&amp;rsquo;s a viable business model, I don&amp;rsquo;t know of anyone pursuing
it. Again, if you have other information, please let me know.&lt;/p&gt;

&lt;h2 id=&#34;integrated-offerings:aedb8a7ea38a4e095f87fc7c5e54b3a9&#34;&gt;Integrated Offerings&lt;/h2&gt;

&lt;p&gt;Most of the systems are integrated into a larger platform or framework
of additional offerings. That&amp;rsquo;s obvious in the case of Oracle; everyone
knows that. Virtuoso has a lot of additional tools, libraries, etc.,
largely focused on Linked Data, but also including a full RDBMS, XML
support, etc. Judging informally, I would say Oracle and Virtuoso have
the biggest spread of integrated offerings to complement their respective
RDF systems. AllegroGraph has a wide variety of analytic systems that
are integrated with it, as well as editors, the RacerPro OWL reasoner,
etc. OWLIM has integrated NLP and related analytic tools, etc. Talis
Platform takes a slightly different approach; it includes an RDF database,
but it emphasizes the integrated offerings: the Linked Data publishing
platform, etc.&lt;/p&gt;

&lt;p&gt;The outliers here are 5Store and BigData. As far as I know, 5Store is an RDF
database only, more or less. I am not certain about BigData: it has some
extensions (reasoning, temporal, HA); but I don&amp;rsquo;t know their status.&lt;/p&gt;

&lt;h2 id=&#34;focus-on-scalability:aedb8a7ea38a4e095f87fc7c5e54b3a9&#34;&gt;Focus on Scalability&lt;/h2&gt;

&lt;p&gt;This one is semi-technical: the marketing of each system explicitly focuses
on database scalability as the primary metric of evaluation. The marketing
in the RDF database market, such as it is, reminds me a lot of Carl Sagan:
billions and billions of stars, er&amp;hellip;, I mean triples. The talk is not
of transactions per second or average query times for complex OLAP-style
queries. The most common metrics are loading time and the raw number of
triples. Several of the systems are built around some kind of distributed
or clustered architecture, the point of which is scalability (though
reliability is also a technical factor, but not one which any system except
BigData emphasizes). AllegroGraph is a near outlier here since it&amp;rsquo;s now
being marketed explicitly for OLTP or transactional loads. Talis Platform
is also an outlier since it doesn&amp;rsquo;t especially emphasize scalability in its
marketing, which is not to say that it isn&amp;rsquo;t scalable (I don&amp;rsquo;t know either
way).&lt;/p&gt;

&lt;p&gt;Recall: my point here isn&amp;rsquo;t purely technical; but, rather, how are each of
these systems marketed, what is their commercial messaging or positioning,
who&amp;rsquo;s selling software, etc.&lt;/p&gt;

&lt;h2 id=&#34;reasoning-required:aedb8a7ea38a4e095f87fc7c5e54b3a9&#34;&gt;Reasoning Required&lt;/h2&gt;

&lt;p&gt;Some kind of reasoning is part of all, or nearly all, of the systems in
the RDF database market. This is an important point to emphasize, since
it sometimes seems that there is a split between the RDF &lt;em&gt;qua&lt;/em&gt; graph data
structure and RDF/OWL &lt;em&gt;qua&lt;/em&gt; knowledge representation camps. That so-called
split isn&amp;rsquo;t really evident when we look at the offerings in the RDF database
market:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Oracle&amp;rsquo;s system contains a forward-chaining reasoner at (more or less) the
OWL2 RL level&lt;/li&gt;
&lt;li&gt;Virtuoso appears to prefer backward chaining over an assortment of OWL and
RDFS property types&lt;/li&gt;
&lt;li&gt;AllegroGraph supports what they call &amp;#8220;RDFS++ reasoning&amp;#8221;, which
appears to be pretty similar to Virtuoso&amp;rsquo;s property-based reasoning; it also
supports Prolog rules&lt;/li&gt;
&lt;li&gt;BigData supports RDFS plus some OWL properties&lt;/li&gt;
&lt;li&gt;OWLIM supports RDFS, OWL Horst, and OWL2 RL reasoning&lt;/li&gt;
&lt;li&gt;5Store is an outlier here: it does not support reasoning of any kind (that I can determine)&lt;/li&gt;
&lt;li&gt;Talis Platform is an outlier, too: it does not support reasoning of any kind (that I can determine)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;There aren&amp;rsquo;t any systems supporting more expressivity than OWL2 RL; but that
is what we should expect to see, given the technical affinities between
databases, rule engines, RDFS, and OWL2 RL.&lt;/p&gt;

&lt;h2 id=&#34;license-costs-and-pricing-models:aedb8a7ea38a4e095f87fc7c5e54b3a9&#34;&gt;License Costs and Pricing Models&lt;/h2&gt;

&lt;p&gt;Licensing fees and pricing models are a mixed bag:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;OWLIM does per core licensing (900 Euros per core)&lt;/li&gt;
&lt;li&gt;Oracle Semantic Technologies is a free add-on to the Oracle Spatial extension&lt;/li&gt;
&lt;li&gt;BigData: unknown&lt;/li&gt;
&lt;li&gt;AllegroGraph: appears to be licensed per-CPU and list prices don&amp;rsquo;t seem to be publicly available&lt;/li&gt;
&lt;li&gt;5Store: unknown&lt;/li&gt;
&lt;li&gt;Talis Platform: Software as a Service model; has both free and for-pay options&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;sparql-1-1-participation:aedb8a7ea38a4e095f87fc7c5e54b3a9&#34;&gt;SPARQL 1.1 Participation&lt;/h2&gt;

&lt;p&gt;The RDF database market achieves a high degree of core interoperability:
every system implements SPARQL. There may be interoperability issues at
the edge of these offerings, since most of those extensions are relatively
tool-specific.&lt;/p&gt;

&lt;p&gt;That said, it&amp;rsquo;s interesting to look at which vendors are participating in
the ongoing efforts to specify SPARQL 1.1. Talis, Oracle, Virtuoso, and
5Store are active in the SPARQL WG; BigData, OWLIM, and AllegroGraph are not
participating publicly in the WG.&lt;/p&gt;

&lt;h2 id=&#34;conclusions:aedb8a7ea38a4e095f87fc7c5e54b3a9&#34;&gt;Conclusions&lt;/h2&gt;

&lt;p&gt;What&amp;rsquo;s the upshot of all this? The market has some continuities
(standards-respecting, reasoning offerings pretty uniform, focus on
scalability) and some discontinuities (pricing, degree of integration with
other systems, business model). It&amp;rsquo;d be interesting to speculate about
which is the commercial leader, in the sense of largest volume of licensing
revenue. There do seem to be some parts of the market that aren&amp;rsquo;t being
pursued commercially. I wonder, too, if we&amp;rsquo;ll see any consolidation or
shakeout in this market anytime soon?&lt;/p&gt;

&lt;p&gt;What do you think about the commercial RDF database market? Are your use
cases and requirements for a commercial system being met by the current
offerings?&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>