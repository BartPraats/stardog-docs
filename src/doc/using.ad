= Using Stardog

Stardog supports
http://www.cambridgesemantics.com/semantic-university/sparql-by-example[SPARQL],
the W3C standard for <<Querying,querying>> RDF graphs, as well as a range of other
capabilities, including <<Updating,updating>>,
<<Versioning,versioning>> <<Exporting,exporting>>,
<<Searching,searching>>, <<Obfuscating,obfuscating>>, and
<<Browsing,browsing>> graph data.

== Querying

Stardog supports SPARQL 1.1 and also the
http://www.w3.org/TR/2012/CR-sparql11-entailment-20121108/[OWL 2
Direct Semantics entailment regime].

To execute a SPARQL query against a Stardog database, use the `query`
subcommand:

[source,bash]
----
$ stardog query myDb "select * where { ?s ?p ?o }"
----

Detailed information on using the query command in Stardog can be found
on its link:man/query-execute.html[`man` page].

=== DESCRIBE

SPARQL's `DESCRIBE` keyword is deliberately underspecified;
vendors are free to do, for good or bad, whatever they want.
In Stardog a `DESCRIBE <theResource>` query retrieves the predicates and
objects for all the triples for which `<theResource>` is the subject.
There are, of course, about seventeen thousand other ways to implement
`DESCRIBE`; we've implemented four or five of them and may expose them to
users in a future release of Stardog _based on user feedback and requests_.

=== Query Functions

Stardog supports all of the functions in SPARQL, as well as some others from
XPath and SWRL. Any of these functions can be used in queries or rules. Some
functions appear in multiple namespaces, but all of the namespaces will work.

See <<SPARQL Query Functions>> for the complete list.

=== Federated Queries

Stardog 3.0 adds support for the
http://www.w3.org/TR/sparql11-federated-query/[SERVICE]
keywordfootnote:[The last SPARQL 1.1 feature that we didn't support.]
which allows users to query distributed RDF via SPARQL-compliant data
sources. You can use this to federate queries between several Stardog
database or Stardog and other public endpoints.

NOTE: Stardog 3.0 doesn't support variables for the service URL
(`SERVICE ?serviceURL`).

Stardog ships with a default `Service` implementation which uses
SPARQL Protocol to send the service fragment to the remote endpoint
and retrieve the results. Any endpoint that conforms to the SPARQL
protocol can be used.

The Stardog SPARQL endpoint is `http://<server>:<port>/{db}/query`.

==== HTTP Authentication

Stardog requires authentication. If the endpoint you're referencing
with the `SERVICE` keyword requires HTTP authentication, credentials
are stored in a <<Using a Password File,password file>> called
`services.sdpass` located in `STARDOG_HOME` directory. The default
`Service` implementation assumes HTTP BASIC authentication; for
services that use DIGEST auth, or a different authentication mechanism
altogether, you'll need to implement a custom `Service`
implementation.

////
=== Querying RDBMS via Virtual Graphs

Sometimes enterprise information belongs to or in a Stardog graph but for
various reasons the upstream or canonical data source should not be disturbed,
consolidated, or decommissioned. In those (and other) cases it makes sense to
use Stardog's R2RMLfootnote:[See the http://www.w3.org/TR/r2rml/[R2RML spec] for
more information about R2RML.] mapping feature to create virtual graphs, that
is, mappings between a Stardog graph and external data sources such that Stardog
will query the external data sources--by rewriting SPARQL to SQL
automatically--as if they were actually materialized in Stardog.

See the <<Virtual Graphs>> chapter for configuration and usage.
////

== Updating

There are many ways to update the data in a Stardog database; two of
the most commonly used methods are the CLI and SPARQL Update queries,
each of which are discussed below.

=== SPARQL Update

SPARQL 1.1 Update can be used to insert RDF into or delete RDF from a Stardog
database using SPARQL query forms `INSERT` and `DELETE`, respectively.

[source,SPARQL]
----
PREFIX dc: <http://purl.org/dc/elements/1.1/>
PREFIX ns: <http://example.org/ns#>
INSERT DATA
{ GRAPH <http://example/bookStore> { <http://example/book1>  ns:price  42 } }
----

An example of deleting RDF:

[source,SPARQL]
----
PREFIX dc: <http://purl.org/dc/elements/1.1/>

DELETE DATA
{
  <http://example/book2> dc:title "David Copperfield" ;
                         dc:creator "Edmund Wells" .
}
----

Or they can be combined with `WHERE` clauses:

[source,SPARQL]
----
PREFIX foaf:  <http://xmlns.com/foaf/0.1/>

WITH <http://example/addresses>
DELETE { ?person foaf:givenName 'Bill' }
INSERT { ?person foaf:givenName 'William' }
WHERE
  { ?person foaf:givenName 'Bill' }
----

NOTE: Per the SPARQL Update spec, Stardog treats Update queries as
implicitly transactional and atomic. Since Stardog does not support
nested transactions, it will not (currently) support an Update query
in an open transaction.footnote:[User feedback about this limitation
is welcomed.]

=== Adding Data with the CLI

As of Stardog {version}, the most efficient way to load data into Stardog is at database creation
time. See the <<Creating a Database>> section for bulk
loading data at database creation time. To add data to an existing
Stardog database, use the link:man/data-add.html[`add`] command:

[source,bash]
----
$ stardog data add myDatabase 1.rdf 2.rdf 3.rdf
----

The optional arguments are `-f` (or `--format`) to specify the RDF
serialization type of the files to be loaded; if you specify the wrong
type, `add` will fail. If you don't specify a type, Stardog will try to
determine the type on its own based on the file extension. For example,
the files that have names ending with '.ttl' will be parsed with Turtle
syntax. If you specify a type, then all the files being loaded must of
that same type.

If you want to add data to a named graph, specify it via the
`--named-graph` or `-g` options.

=== Removing Data with the CLI

To remove data, use link:/man/data-remove.html[`remove`] with the
following input(s):

1.  one Named Graph, _or_
2.  one or more files containing RDF (in some recognized serialization
    format, i.e., RDF/XML, Turtle, Trig), _or_
3.  one Named Graph and one or more RDF files.

For example,

[source,bash]
----
$ stardog data remove -g http://foo myDatabase
----

will remove the named graph `\http://foo` and all its triples from
`myDatabase`.

[source,bash]
----
$ stardog data remove myDatabase 1.rdf
----

will remove the triples in `1.rdf` from (the default graph of)
`myDatabase`.

[source,bash]
----
$ stardog data remove -g http://foo -f TURTLE myDatabase 2.rdf 3.rdf
----

will remove the triples in the Turtle files `2.rdf` and `3.rdf` from the
named graph `\http://foo` of `myDatabase`.

Strict or loose parsing may be set for the input payload by using
`--strict-parsing=TRUE|FALSE`.

=== How Stardog Handles RDF Parsing

RDF parsing in Stardog is strict: it requires typed RDF literals to
match their explicit datatypes, URIs to be well-formed, etc. In some
cases, strict parsing isn't idealâ€”it may be disabled using the
`--strict-parsing=FALSE`.

However, even with strict parsing disabled, Stardog's RDF parser may
encounter parse errors from which it cannot recover. And loading data in
lax mode may lead to unexpected SPARQL query results. For example,
malformed literals (`"2.5"^^xsd:int`) used in filter evaluation may lead
to undesired results.

== Versioning

Stardog supports graph change management capability that lets users track changes between
revisions of a Stardog database, add comments and other metadata to the revisions,
extract diffs between those revisions, tag revisions with labels, and query over the revision history of the database using SPARQL.

Versioning support for a database is disabled by default but can be enabled at any time by setting the configuration option `versioning.enabled` to true. For example, you can create a database with versioning support as follows:

[source,bash]
----
$ stardog-admin db create -o versioning.enabled=true -n myDb
----

This option can also be set after database creation using the `stardog-admin metadata set` command.

The following examples give a *very brief overview* of this capability;
see the <<Man Pages>> for all the details.

=== Committing Changes

Commit a new version by adding and removing triples specified in files.
Different from the `data add/remove` commands, `commit` allows one to add and
remove triples in one commit and to associate a commit message.

NOTE: Removals are performed before additions.

To commit changes:

[source,bash]
----
$ stardog vcs commit --add add_file1.ttl add_file2.ttl --remove remove_file.ttl -m "This is an example commit" myDb
----

=== Viewing Revisions

To see all revisions (commits) in a database:

[source,bash]
----
$ stardog vcs list myDb
$ stardog vcs list --committer userName myDb
----

The output can be tweaked using `--after`, `--before`, and `--committer`.

=== Reverting Revisions

You can revert specific revisions, ranges, etc.

[source,bash]
----
$ stardog vcs revert myDb
$ stardog vcs revert myDb de44369d-cc7b-4244-a3fb-3f6e271420b0
----

=== Viewing Diffs

You can also see the differences between revisions; by default, between the
head version and its previous versions or the changes in a specific commit,
respectively:

[source,bash]
----
$ stardog vcs diff myDb
$ stardog vcs diff myDb de44369d-cc7b-4244-a3fb-3f6e271420b0
----

NOTE: Diffs are represented as SPARQL Update queries so that they may be used as
a kind of graph patch.

=== Using Tags

You can also create, drop, list tags, i.e., named revisions:

[source,bash]
----
$ stardog vcs tag --list myDb
----

=== Querying the Revision History

The revision history of the database is represented as RDF using the W3C PROV
vocabulary and can be queried using SPARQL:footnote:[Find another database that can
do that!]

[source,bash]
----
$ stardog vcs query myDb 'SELECT...'
----

== Exporting

To export data from a Stardog database back to RDF,
link:/man/data-export.html[`export`] is used by specifying

1. the name of the database to export
2. optionally, the URIs of the named graphs to export if you wish to
    export specific named graphs only. Keywords `DEFAULT` and `ALL` can be used as values of 
    the `--named-graph` parameter to export the default graph and all graphs, respectively
3. the export format: `N-TRIPLES, RDF/XML, TURTLE, TRIG`. The default is
    `N-TRIPLES`. `TRIG` must be used when exporting the entire database
    if the database contains triples inside named graphs
4. a file to export to

For example,

[source,bash]
----
$ stardog data export --format TURTLE myDatabase myDatabase_output.ttl

$ stardog data export --named-graph http://example.org/context myDatabase myDatabase_output.nt
----

== Searching

Stardog includes an RDF-aware semantic search capability: it will index
RDF literals and supports information retrieval-style queries over
indexed data. See <<Managing Search>> for more details.

=== Indexing Strategy

The indexing strategy creates a "search document" per RDF literal. Each
document consists of the following fields: literal ID; literal value;
and contexts.

See <<User-defined Lucene Analyzer>> for details on customizing
Stardog's search programmatically.

=== Search in SPARQL

We use the predicate `\http://jena.hpl.hp.com/ARQ/property#textMatch` to
access the search index in a SPARQL query.

The `textMatch` function has one required argument, the search query in Lucene syntax.
It also has two optional arguments.  The first is the score threshold; results
whose score is *below* this number are not included in the results.  The second
is the maximum number of results to return from Lucene.  When not specified,
the default limit is `50`.  When a `LIMIT` is specified in the SPARQL query,
it does not affect the full-text search, that only restricts the size of
the final result set.

For example,

[source,SPARQL]
----
SELECT DISTINCT ?s ?score
WHERE {
?s ?p ?l.
( ?l ?score ) <http://jena.hpl.hp.com/ARQ/property#textMatch> ( 'mac' 0.5 50 ).
}
----

This query selects the top 50 literals, and their scores, which match
'mac' and whose scores are above a threshold of 0.5. These literals are
then joined with the generic BGP `?s ?p ?l` to get the resources (?s)
that have those literals. Alternatively, you could use
`?s rdf:type ex:Book` if you only wanted to select the books which
reference the search criteria; you can include as many other BGPs as
you like to enhance your initial search results.

==== Escaping Characters in Search

The "/" character must be escaped because Lucene says so. In fact,
there are several characters that are part of Lucene's query syntax
that must be
http://lucene.apache.org/core/4_0_0/queryparser/org/apache/lucene/queryparser/classic/package-summary.html#Escaping_Special_Characters[escaped].

=== Searching with the Command Line

First, check out the
link:/man/query-search.html[`search` man page]:

[source,bash]
----
$ stardog help query search
----

Okay, now let's do a search over the O'Reilly book catalog in RDF for
everything mentioning "html":

[source,bash]
----
$ stardog query search -q "html" -l 10 catalog
----

The results?

[source]
----
Index    Score    Hit
====================
0    6.422    urn:x-domain:oreilly.com:product:9780596527402.IP
1    6.422    urn:x-domain:oreilly.com:product:9780596003166.IP
2    6.422    urn:x-domain:oreilly.com:product:9781565924949.IP
3    6.422    urn:x-domain:oreilly.com:product:9780596002251.IP
4    6.422    urn:x-domain:oreilly.com:product:9780596101978.IP
5    6.422    urn:x-domain:oreilly.com:product:9780596154066.IP
6    6.422    urn:x-domain:oreilly.com:product:9780596157616.IP
7    6.422    urn:x-domain:oreilly.com:product:9780596805876.IP
8    6.422    urn:x-domain:oreilly.com:product:9780596527273.IP
9    6.422    urn:x-domain:oreilly.com:product:9780596002961.IP
----

=== Query Syntax

Stardog search is based on Lucene 4.2.0: we support all of the
http://lucene.apache.org/core/4_2_0/queryparser/org/apache/lucene/queryparser/classic/package-summary.html#package_description[search modifiers]
that Lucene supports, with the exception of fields.

- wildcards: `?` and `*`
- fuzzy: `~` and `~` with similarity weights (e.g. `foo~0.8`)
- proximities: `"semantic web"~5`
- term boosting
- booleans: `OR`, `AND`, `NOT`, +`, and `-`.
- grouping

For a more detailed discussion, see the http://lucene.apache.org/core/4_2_0/queryparser/org/apache/lucene/queryparser/classic/package-summary.html#package_description[Lucene docs].

== Obfuscating

When sharing sensitive RDF data with others, you might
want to (selectively) obfuscate it so that sensitive bits are not present,
but non-sensitive bits remain. For example, this feature can be used to
submit Stardog bug reports using sensitive data.

Data obfuscation works much the same way as the `export` command and supports
the same set of arguments:

[source,bash]
----
$ stardog data obfuscate myDatabase obfDatabase.ttl
----

By default, all URIs, bnodes, and string literals in the database will
be obfuscated using the SHA256 message digest algorithm. Non-string
typed literals (numbers, dates, etc.) are left unchanged as well as
URIs from built-in namespaces (`RDF`, `RDFS`, and `OWL`). It's
possible to customize obfuscation by providing a configuration file.

[source,bash]
----
$ stardog data obfuscate --config obfConfig.ttl myDatabase  obfDatabase.ttl
----

The configuration specifies which URIs and strings will be obfuscated by
defining inclusion and exclusion filters. See the example configuration file
provided in the distribution for details.

Once the data is obfuscated, queries written against the original data will
no longer work. Stardog provides query obfuscation capability, too, so that
queries can be executed against the obfuscated data. If a custom configuration
file is used to obfuscate the data, then the same configuration should be used
for obfuscating the queries as well:

[source,bash]
----
$ stardog query obfuscate --config obfConfig.ttl myDatabase myQuery.sparql > obfQuery.ttl
----
include::console.ad[]

include::manpages.ad[]
