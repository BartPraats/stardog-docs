== Frequently Asked Questions

Some frequently asked questions for which we have answers.

=== Why can't I load Dbpedia (or other RDF) data?

Question:: I get a parsing error when loading Dbpedia or some other RDF. What can I do?

Answer:: First, it's not a bad thing to expect data providers to publish valid data. Second, it is, apparently, a very naive thing to expect data providers to publish valid data...
+
Stardog supports a loose parsing mode which will ignore certain kinds of data invalidity and may allow you to load invalid data. See `strict.parsing` in <<Configuration Options>>.

=== Why doesn't search work?

Question:: I created a database but search doesn't work.

Answer:: Search is disabled by default; you can enable it at database creation
time, or at any subsequent time, using the Web Console or by using
link:/man/metadata-set.html[`metadata set`] CLI. It can be enabled using link:/man/db-create.html[`db
create`] too.

=== Why don't my queries work?!

Question:: I've got some named graphs and blah blah my queries don't work blah blah.

Answer::

Queries with FROM NAMED with a named graph that is not **in** Stardog will not cause
Stardog to download the data from an arbitrary HTTP URL and include it in the
query. _Stardog will only evaluate queries over data that has been loaded into
it_.
+
SPARQL queries without a context or named graph are executed against **the
default, unnamed graph**. In Stardog, **the default graph is not the union of all
the named graphs and the default graph**. This behavior is configurable via
the `query.all.graphs` configuration parameter.

=== SPARQL 1.1

Question:: Does Stardog support SPARQL 1.1?

Answer:: Yes.

=== Deadlocks and Slowdowns

Question:: Stardog slows down or deadlocks?! I don't understand why,
I'm just trying to send some queries and do something with the
results...in a tight inner loop of doom!

Answer:: Make sure you are closing result sets (`TupleQueryResult`
and `GraphQueryResult`; or the Jena equivalents) when you are done with
them. These hold open resources both on the client and on the server and
failing to close them when you are done will cause files, streams,
lions, tigers, and bears to be held open. If you do that enough, then
you'll eventually exhaust all of the resources in their respective
pools, which can cause slowness or, in some cases, deadlocks waiting for
resources to be returned.
+
Similarly close your connections when you are done with them. Failing to
close `Connections`, `Iterations`, `QueryResults`, and other *closeable*
objects will lead to undesirable behavior.

=== Bulk Update Performance

Question:: I'm adding one triple at a time, in a tight loop, to
Stardog; is this the ideal strategy with respect to performance?

Question:: I'm adding millions of triples to Stardog and I'm
wondering if that's the best approach?

Answer:: The answer to both questions is "not really"...Generally overall update
performance is best if you write between 1k and 100k triples at a time. You may
need to experiment to find the sweet spot with respect to your data, database
size, the size of the differential index, and update frequency.

=== Public Endpoint

Question:: I want to use Stardog to serve a public SPARQL endpoint;
is there some way I can do this without publishing user account
information?

Answer:: We don't necessarily recommend this, but it's possible.
Simply pass `--disable-security` to `stardog-admin` when you start the
Stardog Server.  This *completely* disables security in Stardog which
will let users access the SPARQL endpoint, and all other functionality,
without needing authorization.

=== Remote Bulk Loading

Question:: I'm trying to create a database and bulk load files from
my machine to the server and it's not working, the files don't seem to
load, what gives?

Answer:: Stardog does not transfer files during database creation to
the server, sending big files over a network kind of defeats the purpose
of blazing fast bulk loading. If you want to bulk load files from your
machine to a remote server, copy them to the server and bulk load them.

=== Canonicalized Literals

Question:: Why doesn't my literal look the same as I when I added it to Stardog?

Answer:: Stardog performs
http://docs.stardog.com/java/snarl/com/complexible/stardog/index/IndexOptions.html#CANONICAL_LITERALS[literal
canonicalization] by default. This can be turned off by setting
`index.literals.canonical` to `false`. See <<Configuration Options>> for the details.

=== Cluster Isn't Working

Question:: I've setup Stardog Cluster, but it isn't working and I have
`NoRouteToHostException` exceptions all over my Zookeeper log.

Answer:: Typically--but especially on Red Hat Linux and its
variants--this means that `iptables` is blocking one, some, or all of
the ports that the Cluster is trying to use. You can disable
`iptables` or, better yet, configure it to unblock the ports Cluster
is using.

=== Client Connection Isn't Working

Question:: I'm getting a `ServiceConfigurationError` saying that `SNARLDriver` could not
be instantiated.

Answer:: Make sure that your classpath includes all Stardog JARs and that the user executing your
code has access to them.

=== Loading Compressed Data

Question:: How can I load data from a compressed format that Stardog doesn't support without decompressing the file?

Answer:: Stardog supports several compression formats by default (zip, gzip, bzip2) so files compressed with those 
formats can be passed as input directly without decompression. Files compressed with other formats can also be loaded
to Stardog by decompressing them on-the-fly using http://en.wikipedia.org/wiki/Named_pipe[named pipes] in Unix-like
systems. The following example shows using a named pipe where the decompressed data is sent directly to Stardog
without being writing to disk.

[source,bash]
----
$ mkfifo some-data.rdf 
$ xz -dc some-data.rdf.xz > some-data.rdf &
$ stardog-admin db create -n test some-data.rdf
----
